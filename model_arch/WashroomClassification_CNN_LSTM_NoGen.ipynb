{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iqeUJqyp2Q94"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "import albumentations as A\n",
        "\n",
        "import keras\n",
        "from keras import layers, models\n",
        "import h5py\n",
        "import shutil\n",
        "import gc\n",
        "\n",
        "\n",
        "os.environ[\"KERAS_BACKEND\"] = \"torch\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWNz103a212Q"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJR5erXt237i"
      },
      "outputs": [],
      "source": [
        "def getHDF5Files(path):\n",
        "    hdf5_files = []\n",
        "    data_folders = os.listdir(path)\n",
        "    filter_file = lambda x: x.endswith('.h5')\n",
        "    #filter_file = lambda x: x.endswith('.h5') and not (\"ToiletSit2\" in x) and not (\"ToiletSit3\" in x) and not (\"ToiletStand2\" in x) and not (\"ToiletStand3\" in x)\n",
        "    chunks = list(filter(filter_file, os.listdir(path)))\n",
        "    for chunk in chunks:\n",
        "        filePath = os.path.join(path, chunk)\n",
        "        hdf5_files.append(filePath)\n",
        "    return hdf5_files\n",
        "\n",
        "\n",
        "def normalize_middle_dimensions(data):\n",
        "    \"\"\"\n",
        "    Normalize only the middle dimensions (64, 256) of the data with shape (X, 64, 256, 1)\n",
        "    using standard normalization (z-score normalization).\n",
        "\n",
        "    Args:\n",
        "        data (numpy array): The input data of shape (X, 64, 256, 1).\n",
        "\n",
        "    Returns:\n",
        "        numpy array: Normalized data where only the (64, 256) dimensions are normalized.\n",
        "    \"\"\"\n",
        "    # Compute mean and standard deviation along the (64, 256) dimensions\n",
        "    mean = np.mean(data, axis=(1, 2), keepdims=True)\n",
        "    std = np.std(data, axis=(1, 2), keepdims=True)\n",
        "\n",
        "    # Avoid division by zero by ensuring std is not zero\n",
        "    epsilon = 1e-8\n",
        "    std_adjusted = np.where(std > 0, std, epsilon)\n",
        "\n",
        "    # Apply standard normalization\n",
        "    normalized_data = (data - mean) / std_adjusted\n",
        "\n",
        "    return normalized_data\n",
        "\n",
        "def extract_data_from_hdf5(file_paths, reshaped_dim, n_channels, timesteps, UseWeights = False, weights= None, shuffle = True, stride=3, Augmentation=True):\n",
        "\n",
        "    #azimuth = None\n",
        "    elevation = None\n",
        "    doppler = None\n",
        "    labels = None\n",
        "\n",
        "    augmentation_pipeline = A.Compose([\n",
        "        A.VerticalFlip(p=0.5)  # Vertical flip with a 50% probability\n",
        "    ])\n",
        "\n",
        "    for file_path in file_paths:\n",
        "        try:\n",
        "            with h5py.File(file_path, 'r') as hdf5:\n",
        "                #azimuth_data = hdf5[\"Azimuth\"][:]\n",
        "                elevation_data = hdf5[\"Elevation\"][:]\n",
        "                doppler_data = hdf5[\"Doppler\"][:]\n",
        "                label_data = hdf5[\"label\"][:]\n",
        "                length = int(len(elevation_data)//stride) - timesteps\n",
        "\n",
        "                #azimuth_reshaped = np.empty((length, timesteps,  *reshaped_dim, n_channels), dtype=np.float32)\n",
        "                elevation_reshaped = np.empty((length, timesteps, *reshaped_dim, n_channels), dtype=np.float32)\n",
        "                doppler_reshaped = np.empty((length, timesteps, *reshaped_dim, n_channels), dtype=np.float32)\n",
        "                label_reshaped = np.empty((length), dtype=np.int32)\n",
        "\n",
        "                for i in range(length):\n",
        "                  for step in range(timesteps):\n",
        "                    #azimuth_reshaped[i, step] = np.reshape(azimuth_data[stride*i + step], (*reshaped_dim, n_channels))\n",
        "                    elevation_reshaped[i, step] = np.reshape(elevation_data[stride*i + step], (*reshaped_dim, n_channels))\n",
        "                    doppler_reshaped[i, step] = np.reshape(doppler_data[stride*i + step], (*reshaped_dim, n_channels))\n",
        "\n",
        "                    if Augmentation:\n",
        "                      #azimuth_reshaped[i, step] = augmentation_pipeline(image=azimuth_reshaped[i, step])[\"image\"]\n",
        "                      elevation_reshaped[i, step] = augmentation_pipeline(image=elevation_reshaped[i, step])[\"image\"]\n",
        "                      doppler_reshaped[i, step] = augmentation_pipeline(image=doppler_reshaped[i, step])[\"image\"]\n",
        "\n",
        "                  label_reshaped[i] = label_data[stride*i]\n",
        "                  if (label_reshaped[i] == 6) or (label_reshaped[i] == 7) or (label_reshaped[i] == 8):\n",
        "                    label_reshaped[i] = 6\n",
        "\n",
        "                  if UseWeights:\n",
        "                    elevation_reshaped[i] = elevation_reshaped[i] * weights[label_reshaped[i]][0]\n",
        "                    doppler_reshaped[i] = doppler_reshaped[i] *  weights[label_reshaped[i]][1]\n",
        "\n",
        "\n",
        "\n",
        "                if elevation is None:\n",
        "                    #azimuth = azimuth_reshaped\n",
        "                    elevation = elevation_reshaped\n",
        "                    doppler = doppler_reshaped\n",
        "                    labels = label_reshaped\n",
        "                else:\n",
        "                    #azimuth = np.concatenate((azimuth, azimuth_reshaped), axis=0)\n",
        "                    elevation = np.concatenate((elevation, elevation_reshaped), axis=0)\n",
        "                    doppler = np.concatenate((doppler, doppler_reshaped), axis=0)\n",
        "                    labels = np.concatenate((labels, label_reshaped), axis=0)\n",
        "\n",
        "                #del azimuth_reshaped\n",
        "                del elevation_reshaped\n",
        "                del doppler_reshaped\n",
        "                del label_reshaped\n",
        "                gc.collect()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing file {file_path}: {e}\")\n",
        "    if shuffle:\n",
        "      indices = np.arange(elevation.shape[0])  # Assuming shape[0] is 'length'\n",
        "      np.random.shuffle(indices)\n",
        "      #azimuth = azimuth[indices]\n",
        "      elevation = elevation[indices]\n",
        "      doppler = doppler[indices]\n",
        "      labels = labels[indices]\n",
        "\n",
        "    #normalized_azimuth = normalize_middle_dimensions(azimuth)\n",
        "    normalized_elevation = normalize_middle_dimensions(elevation)\n",
        "    normalized_doppler = normalize_middle_dimensions(doppler)\n",
        "\n",
        "\n",
        "\n",
        "    #del azimuth\n",
        "    del elevation\n",
        "    del doppler\n",
        "    gc.collect()\n",
        "\n",
        "    #return [normalized_azimuth, normalized_elevation, normalized_doppler], labels\n",
        "    return [normalized_elevation, normalized_doppler], labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1aQ1pSF2-i2"
      },
      "outputs": [],
      "source": [
        "#Defining model inputs\n",
        "# Define the model\n",
        "#del model\n",
        "\n",
        "\n",
        "timesteps = 10\n",
        "\n",
        "input1 = keras.Input(shape=(timesteps, 32, 256, 1))\n",
        "input2 = keras.Input(shape=(timesteps, 32, 256, 1))\n",
        "#input3 = keras.Input(shape=(timesteps, 32, 256, 1))\n",
        "\n",
        "#Applying Convolutional Layers\n",
        "\n",
        "\n",
        "#For input 1\n",
        "conv1 = layers.TimeDistributed(layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same' ))(input1)\n",
        "#conv1 = layers.TimeDistributed(layers.Dropout(0.1))(conv1)\n",
        "conv1 = layers.TimeDistributed(layers.MaxPooling2D(pool_size=(2, 2)))(conv1)\n",
        "conv1 = layers.TimeDistributed(layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same' ))(conv1)\n",
        "#conv1 = layers.TimeDistributed(layers.Dropout(0.1))(conv1)\n",
        "conv1 = layers.TimeDistributed(layers.MaxPooling2D(pool_size=(2, 2)))(conv1)\n",
        "conv1 = layers.TimeDistributed(layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same' ))(conv1)\n",
        "#conv1 = layers.TimeDistributed(layers.Dropout(0.1))(conv1)\n",
        "conv1 = layers.TimeDistributed(layers.MaxPooling2D(pool_size=(2, 2)))(conv1)\n",
        "\n",
        "\n",
        "conv1 = keras.ops.expand_dims(conv1, axis=-1)\n",
        "\n",
        "#For input 2\n",
        "conv2 = layers.TimeDistributed(layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same' ))(input2)\n",
        "#conv2 = layers.TimeDistributed(layers.Dropout(0.1))(conv2)\n",
        "conv2 = layers.TimeDistributed(layers.MaxPooling2D(pool_size=(2, 2)))(conv2)\n",
        "conv2 = layers.TimeDistributed(layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same' ))(conv2)\n",
        "#conv2 = layers.TimeDistributed(layers.Dropout(0.1))(conv2)\n",
        "conv2 = layers.TimeDistributed(layers.MaxPooling2D(pool_size=(2, 2)))(conv2)\n",
        "conv2 = layers.TimeDistributed(layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same' ))(conv2)\n",
        "#conv2 = layers.TimeDistributed(layers.Dropout(0.1))(conv2)\n",
        "conv2 = layers.TimeDistributed(layers.MaxPooling2D(pool_size=(2, 2)))(conv2)\n",
        "\n",
        "conv2 = keras.ops.expand_dims(conv2, axis=-1)\n",
        "\n",
        "'''\n",
        "#For input 3\n",
        "conv3 = layers.TimeDistributed(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu', padding='same' ))(input3)\n",
        "conv3 = layers.TimeDistributed(layers.Dropout(0.1))(conv3)\n",
        "conv3 = layers.TimeDistributed(layers.MaxPooling2D(pool_size=(2, 2)))(conv3)\n",
        "conv3 = layers.TimeDistributed(layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same' ))(conv3)\n",
        "conv3 = layers.TimeDistributed(layers.Dropout(0.1))(conv3)\n",
        "conv3 = layers.TimeDistributed(layers.MaxPooling2D(pool_size=(2, 2)))(conv3)\n",
        "conv3 = layers.TimeDistributed(layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same' ))(conv3)\n",
        "conv3 = layers.TimeDistributed(layers.Dropout(0.1))(conv3)\n",
        "conv3 = layers.TimeDistributed(layers.MaxPooling2D(pool_size=(2, 2)))(conv3)\n",
        "\n",
        "conv3 = keras.ops.expand_dims(conv3, axis=-1)\n",
        "'''\n",
        "\n",
        "#Concatenating each Convolutional Layer\n",
        "concatenated = layers.Concatenate(axis=-1)([conv1, conv2])\n",
        "#concatenated = layers.Concatenate(axis=-1)([conv1, conv2, conv3])\n",
        "\n",
        "x = layers.TimeDistributed(layers.Flatten())(concatenated)\n",
        "\n",
        "x = layers.TimeDistributed(layers.Dense(128, activation='relu'))(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "#x = layers.Dropout(0.1)(x)\n",
        "\n",
        "x = layers.LSTM(128, return_sequences=False, activation='relu')(x)\n",
        "#x = layers.BatchNormalization()(x)\n",
        "#x = layers.Dropout(0.1)(x)\n",
        "\n",
        "\n",
        "x = layers.Dense(96, activation='relu')(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "#x = layers.Dropout(0.1)(x)\n",
        "\n",
        "\n",
        "x = layers.Dense(64, activation='relu')(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "#x = layers.Dropout(0.1)(x)\n",
        "\n",
        "\n",
        "x = layers.Dense(32, activation='relu')(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "#x = layers.Dropout(0.1)(x)\n",
        "\n",
        "\n",
        "output = layers.Dense(7, activation='softmax')(x)\n",
        "\n",
        "# Create the model\n",
        "model = models.Model(inputs=[input1, input2], outputs=output)\n",
        "#model = models.Model(inputs=[input1, input2, input3], outputs=output)\n",
        "\n",
        "# Print model summary\n",
        "model.summary()\n",
        "\n",
        "# Setting learning rate\n",
        "optimizer = keras.optimizers.Adam(learning_rate=0.000001)\n",
        "\n",
        "# Compiling model and history\n",
        "model.compile(optimizer=optimizer,\n",
        "            loss='sparse_categorical_crossentropy',\n",
        "            metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mEtd-NT13Ay8"
      },
      "outputs": [],
      "source": [
        "# Training the model\n",
        "#keras.mixed_precision.set_global_policy('float32')\n",
        "#print(model.dtype_policy)\n",
        "Trainpath = '/content/drive/MyDrive/Josh/ProcessedMyData10fps/Unshuffled/Training'\n",
        "Train_hdf5_files = getHDF5Files(Trainpath)\n",
        "Valpath = '/content/drive/MyDrive/Josh/ProcessedMyData10fps/Unshuffled/Validation'\n",
        "Val_hdf5_files = getHDF5Files(Valpath)\n",
        "\n",
        "batch_size = 16\n",
        "reshaped_dim = (32, 256)\n",
        "n_channels = 1\n",
        "timesteps =   10\n",
        "#order of classes 0-toiletSit, 1-ToiletStand, 2-WashHands, 3-Floor, 4-Walk, 5-MultiPerson, 6-Clean\n",
        "#Weights in form [Elevation, Doppler]\n",
        "weights = [[0.9, 0.1], [0.9, 0.1], [0.5, 0.5], [0.9, 0.1], [0.1, 0.9], [0.5, 0.5], [0.2, 0.8]]\n",
        "\n",
        "print(\"Processing Training Data\")\n",
        "x_train, y_train = extract_data_from_hdf5(Train_hdf5_files, reshaped_dim, n_channels, timesteps, UseWeights=True, weights = weights, stride=4, Augmentation=True)\n",
        "print(\"Processing Validation Data\")\n",
        "x_val, y_val = extract_data_from_hdf5(Val_hdf5_files, reshaped_dim, n_channels, timesteps, UseWeights=False, weights = None, stride=timesteps, Augmentation=False)\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "class_weights = class_weight.compute_class_weight(class_weight='balanced',\n",
        "                                                 classes=np.unique(y_train),\n",
        "                                                 y=y_train)\n",
        "\n",
        "# Convert class weights to a dictionary format\n",
        "class_weight_dict = dict(enumerate(class_weights))\n",
        "\n",
        "#callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=6)\n",
        "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=200, validation_data=(x_val, y_val), shuffle=True, class_weight=class_weight_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "waDTnDCrdMqf"
      },
      "outputs": [],
      "source": [
        "\n",
        "model = keras.saving.load_model(\"/content/drive/MyDrive/Josh/Results/LSTM-Tuning/FinalModel/Final-Augment/Model.keras\")\n",
        "\n",
        "\n",
        "reshaped_dim = (32, 256)\n",
        "n_channels = 1\n",
        "timesteps =   10\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mz-jW44ZWaBM"
      },
      "outputs": [],
      "source": [
        "savePath = \"/content/drive/MyDrive/Josh/Results/LSTM-Tuning/FinalModel/Final-Augment\"\n",
        "if not os.path.exists(savePath):\n",
        "  os.makedirs(savePath)\n",
        "model.save(os.path.join(savePath, \"Model.keras\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3q7jduzDM-7"
      },
      "outputs": [],
      "source": [
        "Valpath = '/content/drive/MyDrive/Josh/ProcessedMyData10fps/Unshuffled/Validation'\n",
        "\n",
        "Val_hdf5_files = getHDF5Files(Valpath)\n",
        "\n",
        "\n",
        "reshaped_dim = (32, 256)\n",
        "n_channels = 1\n",
        "timesteps =   10\n",
        "#x_val, y_val = extract_data_from_hdf5(Val_hdf5_files, reshaped_dim, n_channels, timesteps, UseWeights=False, weights = None, stride=timesteps, Augmentation=False)\n",
        "\n",
        "#text_x = x_val\n",
        "#text_y = y_val\n",
        "\n",
        "test_loss, test_acc = model.evaluate(x_val, y_val)\n",
        "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_acc}\")\n",
        "\n",
        "# Predict the labels for the test data\n",
        "y_pred = np.argmax(model.predict(x_val), axis=-1)\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(y_val, y_pred)\n",
        "\n",
        "# Define the save path\n",
        "save_path = '/content/drive/MyDrive/Josh/Results/LSTM-Tuning/FinalModel/Final-Normal'\n",
        "\n",
        "# Compute and plot the confusion matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.colorbar()\n",
        "tick_marks = np.arange(7)  # Adjust this to the number of classes\n",
        "class_labels = ['ToiletSit', 'ToiletStand', 'WashHands', 'WashroomSit', 'WashroomWalk', \"Multiperson\", \"Clean\"]\n",
        "plt.xticks(tick_marks, class_labels, rotation=45)\n",
        "plt.yticks(tick_marks, class_labels)\n",
        "\n",
        "# Annotate the confusion matrix\n",
        "fmt = 'd'\n",
        "thresh = cm.max() / 2.\n",
        "for i in range(cm.shape[0]):\n",
        "    for j in range(cm.shape[1]):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "accuracy = test_acc * 100\n",
        "\n",
        "# Overlay accuracy and voted accuracy below the plot\n",
        "plt.figtext(0.5, 0.01, f\"Accuracy: {accuracy:.2f}%\",\n",
        "            fontsize=12, color=\"black\", horizontalalignment='center')\n",
        "\n",
        "# Finalize the plot\n",
        "plt.tight_layout(rect=[0, 0.05, 1, 1])  # Adjust layout to make space for text\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.savefig(os.path.join(save_path, 'confusion_matrix.png'))  # Save figure\n",
        "plt.show()\n",
        "\n",
        "# Plot training and validation accuracy\n",
        "plt.figure()\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.savefig(os.path.join(save_path, 'accuracy_plot.png'))  # Save figure\n",
        "plt.show()\n",
        "\n",
        "# Plot training and validation loss\n",
        "plt.figure()\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "plt.savefig(os.path.join(save_path, 'loss_plot.png'))  # Save figure\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FktrRG47HR4p"
      },
      "outputs": [],
      "source": [
        "#Voting Algorithm\n",
        "from collections import Counter\n",
        "def replace_with_most_common(data, chunk_size=3):\n",
        "    # Ensure the input list length is a multiple of chunk_size\n",
        "\n",
        "\n",
        "    result = []\n",
        "\n",
        "    for i in range(len(data)//chunk_size):\n",
        "        chunk = data[chunk_size*i:(i+1)*chunk_size]\n",
        "        # Find the most common value in the chunk\n",
        "        most_common = Counter(chunk).most_common(1)[0][0]\n",
        "        # Append the most common value for the whole chunk\n",
        "        result.extend([most_common] * chunk_size)\n",
        "\n",
        "    remainder = len(data) % chunk_size\n",
        "    if remainder > 0:\n",
        "        result.extend(data[-remainder:])\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bHRgKQugpMsI"
      },
      "outputs": [],
      "source": [
        "#Graph of predicted Label vs Real Label over time for each Activity File\n",
        "\n",
        "savePath = \"/content/drive/MyDrive/Josh/Results/LSTM-Tuning/FinalModel/Final-Augment/ByFileValidation\"\n",
        "basePath = '/content/drive/MyDrive/Josh/ProcessedMyData10fps/Unshuffled/Validation'\n",
        "\n",
        "if os.path.exists(savePath):\n",
        "  shutil.rmtree(savePath)\n",
        "os.makedirs(savePath)\n",
        "\n",
        "\n",
        "file_names = getHDF5Files(basePath)\n",
        "\n",
        "MetaRealLabels = []\n",
        "MetaPredictedLabels = []\n",
        "MetaPredictedVotedLabels = []\n",
        "\n",
        "for filePath in file_names:\n",
        "  real_label = []\n",
        "  predicted_label = []\n",
        "  voted_label = []\n",
        "  correct_count = 0\n",
        "  voted_correct_count = 0\n",
        "\n",
        "\n",
        "  file_name = os.path.basename(filePath)\n",
        "  file_name = file_name[:-3]\n",
        "\n",
        "  if not os.path.exists(filePath):\n",
        "    print(\"file not found: \", filePath)\n",
        "    continue\n",
        "\n",
        "  batch_size = 16\n",
        "  reshaped_dim = (32, 256)\n",
        "  n_channels = 1\n",
        "  timesteps =   10\n",
        "\n",
        "\n",
        "  test_data, test_labels = extract_data_from_hdf5([filePath], reshaped_dim, n_channels, timesteps, UseWeights=False, weights = None, stride=timesteps, Augmentation=False)\n",
        "\n",
        "  #test_data = np.array(test_data)\n",
        "  test_labels = np.array(test_labels)\n",
        "\n",
        "  # Predict the labels for the test data\n",
        "  y_pred = np.argmax(model.predict(test_data), axis=-1)\n",
        "\n",
        "  predicted_classes = y_pred\n",
        "  # Extract the predicted class for each sample\n",
        "  length = len(predicted_classes)\n",
        "\n",
        "  voted1 = replace_with_most_common(predicted_classes, chunk_size=5)\n",
        "  voted = replace_with_most_common(voted1, chunk_size=30)\n",
        "\n",
        "  MetaRealLabels.extend(test_labels)\n",
        "  MetaPredictedLabels.extend(predicted_classes)\n",
        "  MetaPredictedVotedLabels.extend(voted)\n",
        "\n",
        "\n",
        "\n",
        "  # Print only the predicted class for each sample\n",
        "  for i in range(length):\n",
        "\n",
        "      predicted_class = predicted_classes[i]\n",
        "      real_class = test_labels[i]\n",
        "      voted_class = voted[i]\n",
        "\n",
        "\n",
        "      if predicted_class == real_class:\n",
        "          correct = \"yes\"\n",
        "          correct_count += 1\n",
        "      if voted_class == real_class:\n",
        "          voted_correct_count += 1\n",
        "      else:\n",
        "          correct = \"no\"\n",
        "\n",
        "      real_label.append(real_class)\n",
        "      predicted_label.append(predicted_class)\n",
        "      voted_label.append(voted_class)\n",
        "\n",
        "\n",
        "  accuracy = (correct_count / length) * 100\n",
        "  voted_accuracy = (voted_correct_count / length) * 100\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #Plotting Code\n",
        "\n",
        "  xaxis = list(range(1, length + 1))\n",
        "\n",
        "  fig, ax = plt.subplots()\n",
        "\n",
        "  # Plot the first list against the x-axis list\n",
        "  ax.plot(xaxis, real_label, label='Real Label', color='b',  linewidth=10)\n",
        "\n",
        "  # Plot the second list against the same x-axis list\n",
        "  ax.plot(xaxis, predicted_label, label='Predicted Label', color='r',linewidth=6)\n",
        "\n",
        "  # Plot the third list against the same x-axis\n",
        "  ax.plot(xaxis, voted_label, label='Voted Label', color='g', linewidth=2)\n",
        "\n",
        "  # Adding labels and title\n",
        "  ax.set_xlabel('Samples (1.66 per second)')\n",
        "  ax.set_ylabel('Label')\n",
        "  ax.set_title(f\"predictions for {file_name}\")\n",
        "\n",
        "  # Adding legend\n",
        "  ax.legend()\n",
        "\n",
        "  # Y Axis\n",
        "  y_ticks = [0, 1, 2, 3, 4, 5, 6]\n",
        "  y_labels = ['ToiletSit', \"ToiletStand\", \"WashHands\", \"Fall\", \"Walk\", 'MultiPerson', \"Clean\"]\n",
        "  ax.set_yticks(y_ticks)\n",
        "  ax.set_yticklabels(y_labels)\n",
        "\n",
        "  # Set the y-axis to start at -1\n",
        "  ax.set_ylim(-1, max(y_ticks) + 1)\n",
        "\n",
        "  ax.text(0.05, 0.95, f\"\\nAccuracy: {accuracy}%\\n\\n\", transform=ax.transAxes,\n",
        "          verticalalignment='top', horizontalalignment='left',\n",
        "          color='green', fontsize=12,  alpha=0.8)\n",
        "\n",
        "  ax.text(0.05, 1, f\"\\nVoted Accuracy: {voted_accuracy}%\\n\\n\", transform=ax.transAxes,\n",
        "          verticalalignment='top', horizontalalignment='left',\n",
        "          color='green', fontsize=12,  alpha=0.8)\n",
        "\n",
        "  # Show plot\n",
        "  #plt.show()\n",
        "  figurepath = savePath + \"/Predictions_\" + file_name + \".png\"\n",
        "  fig.savefig(figurepath)\n",
        "  plt.close(fig)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Confusion Matrix for Voted Labels\n",
        "length = len(MetaPredictedVotedLabels)\n",
        "\n",
        "correct_count = 0\n",
        "voted_correct_count = 0\n",
        "\n",
        "for i in range(length):\n",
        "\n",
        "    real_class = MetaRealLabels[i]\n",
        "    predicted_class = MetaPredictedLabels[i]\n",
        "    voted_class = MetaPredictedVotedLabels[i]\n",
        "\n",
        "    if predicted_class == real_class:\n",
        "        correct_count += 1\n",
        "    if voted_class == real_class:\n",
        "        voted_correct_count += 1\n",
        "\n",
        "accuracy = (correct_count / length) * 100\n",
        "print(\"The Accuracy is \", accuracy, \"%\")\n",
        "voted_accuracy = (voted_correct_count / length) * 100\n",
        "print(\"The Voted Accuracy is \", voted_accuracy, \"%\")\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(MetaRealLabels, MetaPredictedVotedLabels)\n",
        "\n",
        "# Define the save path\n",
        "save_path = '/content/drive/MyDrive/Josh/Results/LSTM-Tuning/FinalModel/Final-Normal'\n",
        "\n",
        "# Compute and plot the confusion matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.colorbar()\n",
        "tick_marks = np.arange(7)  # Adjust this to the number of classes\n",
        "class_labels = ['ToiletSit', 'ToiletStand', 'WashHands', 'WashroomSit', 'WashroomWalk', \"Multiperson\", \"Clean\"]\n",
        "plt.xticks(tick_marks, class_labels, rotation=45)\n",
        "plt.yticks(tick_marks, class_labels)\n",
        "\n",
        "# Annotate the confusion matrix\n",
        "fmt = 'd'\n",
        "thresh = cm.max() / 2.\n",
        "for i in range(cm.shape[0]):\n",
        "    for j in range(cm.shape[1]):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "# Overlay accuracy and voted accuracy below the plot\n",
        "plt.figtext(0.5, 0.01, f\"Accuracy: {accuracy:.2f}%, Voted Accuracy: {voted_accuracy:.2f}%\",\n",
        "            fontsize=12, color=\"black\", horizontalalignment='center')\n",
        "\n",
        "# Finalize the plot\n",
        "plt.tight_layout(rect=[0, 0.05, 1, 1])  # Adjust layout to make space for text\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.savefig(os.path.join(save_path, 'voted_confusion_matrix.png'))  # Save figure\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5fenaqjxWOVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-TA5tdQhcPvk"
      },
      "outputs": [],
      "source": [
        "\n",
        "keras.backend.clear_session()\n",
        "gc.collect()\n",
        "del model"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8hr3O2GTpRKM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}